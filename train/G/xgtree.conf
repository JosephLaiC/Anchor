# General Parameters
# -----------------
# 'booster' : Specifies the booster algorithm to use. Can be 'gbtree' or 'gblinear'.
# 'objective' : Specifies the learning task and the corresponding loss function to optimize.
#               Here, we use 'binary:logistic' for binary classification.

booster = gbtree  # Booster algorithm
objective = binary:logistic  # Learning task and loss function

# Tree Booster Parameters
# ----------------------
# 'eta' : The step size shrinkage used in update to prevent overfitting.
# 'gamma' : The minimum loss reduction required to make a further partition.
# 'min_child_weight' : The minimum sum of instance weight (hessian) needed in a child.
# 'max_depth' : The maximum depth of a tree.

eta = 0.1  # Step size shrinkage
# gamma = 1.0  # Minimum loss reduction
# min_child_weight = 5  # Minimum sum of instance weight
max_depth = 7  # Maximum depth of a tree

# Training Parameters
# ------------------
# 'num_round' : The number of round to do boosting.
# 'save_period' : The number of boosting rounds before a checkpoint is saved.
# 'data' : The path of training data.
# 'test:data' : The path of test data.
# 'name_pred' : The name of the output prediction file.

num_round = 1000  # Number of boosting rounds
save_period = 10  # Checkpoint saving period
data = "train.dat"  # Path of training data
test:data = "test.dat"  # Path of test data
name_pred = "output.dat"  # Name of output prediction file

# Validation and Testing Parameters
# ---------------------------------
# 'eval[test]' : The path of validation data, used to monitor training process.
# 'eval_set' : A list of (data, label) pairs to validate the model on.

# eval[test] = "test"  # Validation set name
# eval_set = [("validation.dat", "validation_label.dat")]  # Validation data and labels
